{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR77+JK/5z17sgsrReEXpv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasmark07/SummerCapstone25/blob/main/Dynamic%20Parking%20Pricing%20System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "A1Eb1hKrrM4C",
        "outputId": "e6bdf778-5ad4-4cf9-ae71-090c4d8917f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pathway\n",
            "  Downloading pathway-0.25.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m300.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.11.15)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (8.2.1)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.4.1)\n",
            "Collecting h3>=4 (from pathway)\n",
            "  Downloading h3-4.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.6.1)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.1.1)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (18.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.32.3)\n",
            "Collecting python-sat>=0.1.8.dev0 (from pathway)\n",
            "  Downloading python_sat-1.8.dev17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting beartype<0.16.0,>=0.14.0 (from pathway)\n",
            "  Downloading beartype-0.15.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (13.9.4)\n",
            "Collecting diskcache>=5.2.1 (from pathway)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting boto3<1.36.0,>=1.26.76 (from pathway)\n",
            "  Downloading boto3-1.35.99-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting aiobotocore==2.17.0 (from pathway)\n",
            "  Downloading aiobotocore-2.17.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.176.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (4.14.1)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.7.3)\n",
            "Collecting jupyter-bokeh>=3.0.7 (from pathway)\n",
            "  Downloading jupyter_bokeh-4.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jmespath>=1.0.1 (from pathway)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting aiohttp-cors>=0.7.0 (from pathway)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting opentelemetry-api>=1.22.0 (from pathway)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk>=1.22.0 (from pathway)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.22.0 (from pathway)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting fs>=2.4.16 (from pathway)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting async-lru>=2.0.4 (from pathway)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.5)\n",
            "Collecting google-cloud-pubsub>=2.21.1 (from pathway)\n",
            "  Downloading google_cloud_pubsub-2.31.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-bigquery~=3.29.0 (from pathway)\n",
            "  Downloading google_cloud_bigquery-3.29.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pydantic~=2.9.0 (from pathway)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.1.44)\n",
            "Collecting deltalake<0.18.0,>=0.17.0 (from pathway)\n",
            "  Downloading deltalake-0.17.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.17.0->pathway)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.35.94,>=1.35.74 (from aiobotocore==2.17.0->pathway)\n",
            "  Downloading botocore-1.35.93-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (2.9.0.post0)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (6.6.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (2.4.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (1.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (1.20.1)\n",
            "INFO: pip is looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting boto3<1.36.0,>=1.26.76 (from pathway)\n",
            "  Downloading boto3-1.35.98-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading boto3-1.35.97-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading boto3-1.35.96-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading boto3-1.35.95-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading boto3-1.35.94-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading boto3-1.35.93-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<1.36.0,>=1.26.76->pathway)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow-hotfix (from deltalake<0.18.0,>=0.17.0->pathway)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting appdirs~=1.4.3 (from fs>=2.4.16->pathway)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from fs>=2.4.16->pathway) (75.2.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.11/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.43->pathway) (4.0.12)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.2.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.7.2)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (24.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.51.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.73.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (5.29.5)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.14.2)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.71.2)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.11/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.7.3)\n",
            "Collecting ipywidgets==8.* (from jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.2)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.46.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.2.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2025.4.0)\n",
            "Collecting comm>=0.1.3 (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.15)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway)\n",
            "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.22.0->pathway)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->pathway) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->pathway) (2025.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (3.8.2)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (2.2.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (3.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.9.0->pathway) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic~=2.9.0->pathway)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->pathway) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->pathway) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->pathway) (2025.7.9)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->pathway) (2.19.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->pathway) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->pathway) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->pathway) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0dev,>=2.0.0->google-cloud-bigquery~=3.29.0->pathway) (1.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
            "Downloading pathway-0.25.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (59.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.17.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading beartype-0.15.0-py3-none-any.whl (777 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deltalake-0.17.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_bigquery-3.29.0-py2.py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_pubsub-2.31.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.1/319.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h3-4.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (985 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m985.8/985.8 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jupyter_bokeh-4.0.5-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_sat-1.8.dev17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading botocore-1.35.93-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, widgetsnbextension, python-sat, pydantic-core, pyarrow-hotfix, opentelemetry-proto, jmespath, jedi, h3, fs, diskcache, comm, beartype, async-lru, aioitertools, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, deltalake, botocore, s3transfer, opentelemetry-semantic-conventions, ipywidgets, aiohttp-cors, aiobotocore, opentelemetry-sdk, jupyter-bokeh, boto3, opentelemetry-exporter-otlp-proto-grpc, google-cloud-pubsub, google-cloud-bigquery, pathway\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 3.34.0\n",
            "    Uninstalling google-cloud-bigquery-3.34.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-3.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiobotocore-2.17.0 aiohttp-cors-0.8.1 aioitertools-0.12.0 appdirs-1.4.4 async-lru-2.0.5 beartype-0.15.0 boto3-1.35.93 botocore-1.35.93 comm-0.2.2 deltalake-0.17.4 diskcache-5.6.3 fs-2.4.16 google-cloud-bigquery-3.29.0 google-cloud-pubsub-2.31.0 h3-4.3.0 ipywidgets-8.1.7 jedi-0.19.2 jmespath-1.0.1 jupyter-bokeh-4.0.5 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 pathway-0.25.0 pyarrow-hotfix-0.7 pydantic-2.9.2 pydantic-core-2.23.4 python-sat-1.8.dev17 s3transfer-0.10.4 widgetsnbextension-4.0.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "1ed425d83f4840b1aa4f3ab617f733f3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install pathway"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *main.py*\n",
        "(includes pricing models, batch processing and Pathway integration.)"
      ],
      "metadata": {
        "id": "l4ONtAFhrji8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "from datetime import datetime\n",
        "import pathway as pw\n",
        "\n",
        "# Define the pricing functions directly\n",
        "def model_1_pricing(current_price, occupancy, capacity, alpha):\n",
        "    \"\"\"Calculates the next price using the Baseline Linear Model.\"\"\"\n",
        "    return current_price + alpha * (occupancy / capacity)\n",
        "\n",
        "def model_2_pricing(base_price, occupancy, capacity, queue_length, traffic_condition, is_special_day, vehicle_type, lambda_val, alpha, beta, gamma, delta, epsilon):\n",
        "    \"\"\"Calculates the price using the Demand-Based Price Function.\"\"\"\n",
        "    # Feature Engineering for VehicleType\n",
        "    vehicle_type_weights = {\n",
        "        'car': 1.0,\n",
        "        'bike': 0.5,\n",
        "        'truck': 1.5,\n",
        "        'cycle': 0.3\n",
        "    }\n",
        "    vehicle_type_weight = vehicle_type_weights.get(vehicle_type, 1.0) # Default to 1.0 if unknown\n",
        "\n",
        "    # Feature Engineering for TrafficConditionNearby\n",
        "    traffic_weights = {\n",
        "        'low': 0.5,\n",
        "        'average': 1.0,\n",
        "        'high': 1.5\n",
        "    }\n",
        "    traffic_level = traffic_weights.get(traffic_condition, 1.0) # Default to 1.0 if unknown\n",
        "\n",
        "    # Calculate demand\n",
        "    demand = alpha * (occupancy / capacity) + beta * queue_length - gamma * traffic_level + delta * is_special_day + epsilon * vehicle_type_weight\n",
        "\n",
        "    # Normalize demand (simple min-max normalization for demonstration, needs proper range based on data analysis)\n",
        "    # Assuming a hypothetical min_demand and max_demand for normalization. These should be derived from data.\n",
        "    min_demand = -5.0\n",
        "    max_demand = 15.0\n",
        "    normalized_demand = (demand - min_demand) / (max_demand - min_demand)\n",
        "    normalized_demand = np.clip(normalized_demand, 0, 1) # Ensure it's between 0 and 1\n",
        "\n",
        "    # Calculate price\n",
        "    price = base_price * (1 + lambda_val * normalized_demand)\n",
        "\n",
        "    # Apply price bounds\n",
        "    min_price = base_price * 0.5\n",
        "    max_price = base_price * 2.0\n",
        "    return np.clip(price, min_price, max_price)\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calculate the great circle distance between two points on the earth (specified in decimal degrees)\"\"\"\n",
        "    R = 6371  # Radius of Earth in kilometers\n",
        "\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "def model_3_pricing(current_price_model2, occupancy, capacity, lat, lon, current_system_code, all_parking_data_at_timestep, base_price):\n",
        "    \"\"\"Calculates the price using the Competitive Pricing Model.\"\"\"\n",
        "    competitive_factor = 0.0\n",
        "    nearby_competitors = []\n",
        "\n",
        "    for idx, competitor_row in all_parking_data_at_timestep.iterrows():\n",
        "        if competitor_row[\"SystemCodeNumber\"] != current_system_code:\n",
        "            distance = haversine(lat, lon, competitor_row[\"Latitude\"], competitor_row[\"Longitude\"])\n",
        "            if distance < 1.0: # Consider competitors within 1 km radius\n",
        "                nearby_competitors.append(competitor_row)\n",
        "\n",
        "    if nearby_competitors:\n",
        "        avg_competitor_price = np.mean([comp[\"Price_Model2\"] for comp in nearby_competitors])\n",
        "\n",
        "        occupancy_rate = occupancy / capacity\n",
        "        if occupancy_rate > 0.8 and avg_competitor_price < current_price_model2:\n",
        "            competitive_factor = -0.1 # Reduce price by 10%\n",
        "        elif avg_competitor_price > current_price_model2 * 1.2: # If competitors are significantly more expensive\n",
        "            competitive_factor = 0.05 # Increase price by 5%\n",
        "\n",
        "    return current_price_model2 * (1 + competitive_factor)\n",
        "\n",
        "# Define the schema for the streaming data (Pathway)\n",
        "class ParkingSchema(pw.Schema):\n",
        "    SystemCodeNumber: str\n",
        "    Capacity: int\n",
        "    Occupancy: int\n",
        "    LastUpdatedDate: str\n",
        "    LastUpdatedTime: str\n",
        "    Latitude: float\n",
        "    Longitude: float\n",
        "    QueueLength: int\n",
        "    TrafficConditionNearby: str\n",
        "    IsSpecialDay: bool\n",
        "    VehicleType: str\n",
        "\n",
        "def batch_processing(dataset_path, output_path):\n",
        "    \"\"\"Process the dataset in batch mode using pandas\"\"\"\n",
        "    print(\"Starting batch processing...\")\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Convert 'LastUpdatedDate' and 'LastUpdatedTime' to datetime objects\n",
        "    df[\"Timestamp\"] = pd.to_datetime(df[\"LastUpdatedDate\"] + \" \" + df[\"LastUpdatedTime\"], format=\"%d-%m-%Y %H:%M:%S\")\n",
        "\n",
        "    # Sort by SystemCodeNumber and Timestamp to ensure correct chronological processing per parking lot\n",
        "    df = df.sort_values(by=[\"SystemCodeNumber\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Initialize 'Price' columns with the base price of $10\n",
        "    df[\"Price_Model1\"] = 10.0\n",
        "    df[\"Price_Model2\"] = 10.0\n",
        "    df[\"Price_Model3\"] = 10.0\n",
        "\n",
        "    # --- Model 1 Implementation ---\n",
        "    alpha_model1 = 0.05 # Example alpha value for Model 1\n",
        "\n",
        "    # Process data for each parking lot independently for Model 1\n",
        "    for system_code in df[\"SystemCodeNumber\"].unique():\n",
        "        lot_data_indices = df[df[\"SystemCodeNumber\"] == system_code].index\n",
        "        current_price = 10.0 # Starting price for each lot\n",
        "        for i, original_idx in enumerate(lot_data_indices):\n",
        "            if i > 0:\n",
        "                current_price = df.loc[lot_data_indices[i-1], \"Price_Model1\"]\n",
        "\n",
        "            new_price = model_1_pricing(current_price, df.loc[original_idx, \"Occupancy\"], df.loc[original_idx, \"Capacity\"], alpha_model1)\n",
        "            df.loc[original_idx, \"Price_Model1\"] = new_price\n",
        "\n",
        "    # --- Model 2 Implementation ---\n",
        "    alpha_model2 = 0.1\n",
        "    beta_model2 = 0.2\n",
        "    gamma_model2 = 0.1\n",
        "    delta_model2 = 0.5\n",
        "    epsilon_model2 = 0.3\n",
        "    lambda_model2 = 0.5\n",
        "\n",
        "    # Process data for each parking lot independently for Model 2\n",
        "    for system_code in df[\"SystemCodeNumber\"].unique():\n",
        "        lot_data_indices = df[df[\"SystemCodeNumber\"] == system_code].index\n",
        "        base_price = 10.0 # Base price for each lot\n",
        "        for i, original_idx in enumerate(lot_data_indices):\n",
        "            new_price = model_2_pricing(\n",
        "                base_price,\n",
        "                df.loc[original_idx, \"Occupancy\"],\n",
        "                df.loc[original_idx, \"Capacity\"],\n",
        "                df.loc[original_idx, \"QueueLength\"],\n",
        "                df.loc[original_idx, \"TrafficConditionNearby\"],\n",
        "                df.loc[original_idx, \"IsSpecialDay\"],\n",
        "                df.loc[original_idx, \"VehicleType\"],\n",
        "                lambda_model2,\n",
        "                alpha_model2,\n",
        "                beta_model2,\n",
        "                gamma_model2,\n",
        "                delta_model2,\n",
        "                epsilon_model2\n",
        "            )\n",
        "            df.loc[original_idx, \"Price_Model2\"] = new_price\n",
        "\n",
        "    # --- Model 3 Implementation ---\n",
        "    # This model requires iterating through time steps to get competitor prices at each step\n",
        "    # We will group by Timestamp to process all parking lots at a given time step together\n",
        "\n",
        "    df[\"Price_Model3\"] = df[\"Price_Model2\"] # Start Model 3 price with Model 2 price\n",
        "\n",
        "    for timestamp in df[\"Timestamp\"].unique():\n",
        "        # Get all parking data for the current timestamp\n",
        "        current_timestep_data = df[df[\"Timestamp\"] == timestamp].copy()\n",
        "\n",
        "        for original_idx in current_timestep_data.index:\n",
        "            system_code = df.loc[original_idx, \"SystemCodeNumber\"]\n",
        "            occupancy = df.loc[original_idx, \"Occupancy\"]\n",
        "            capacity = df.loc[original_idx, \"Capacity\"]\n",
        "            lat = df.loc[original_idx, \"Latitude\"]\n",
        "            lon = df.loc[original_idx, \"Longitude\"]\n",
        "            base_price = 10.0 # Base price for Model 3 is also $10\n",
        "            current_price_model2 = df.loc[original_idx, \"Price_Model2\"]\n",
        "\n",
        "            new_price_model3 = model_3_pricing(\n",
        "                current_price_model2,\n",
        "                occupancy,\n",
        "                capacity,\n",
        "                lat,\n",
        "                lon,\n",
        "                system_code,\n",
        "                current_timestep_data, # Pass data for all lots at this timestamp\n",
        "                base_price\n",
        "            )\n",
        "            df.loc[original_idx, \"Price_Model3\"] = new_price_model3\n",
        "\n",
        "    # Save the processed data with new prices\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Batch processing completed. Output saved to {output_path}\")\n",
        "    return df\n",
        "\n",
        "def streaming_processing(dataset_path, stream_output_path):\n",
        "    \"\"\"Process the dataset in streaming mode using Pathway\"\"\"\n",
        "    print(\"Starting streaming processing with Pathway...\")\n",
        "\n",
        "    try:\n",
        "        # Read the original dataset to extract relevant columns for Pathway\n",
        "        df_original = pd.read_csv(dataset_path)\n",
        "\n",
        "        # Select a subset of columns that are relevant for the Pathway stream\n",
        "        stream_df = df_original[[\n",
        "            'SystemCodeNumber', 'Capacity', 'Occupancy', 'LastUpdatedDate',\n",
        "            'LastUpdatedTime', 'Latitude', 'Longitude', 'QueueLength',\n",
        "            'TrafficConditionNearby', 'IsSpecialDay', 'VehicleType'\n",
        "        ]].copy()\n",
        "\n",
        "        # Save this subset to a temporary CSV file for Pathway to read\n",
        "        stream_file_path = '/tmp/parking_stream_for_pathway.csv'\n",
        "        stream_df.to_csv(stream_file_path, index=False)\n",
        "\n",
        "        # Load the data as a simulated stream using Pathway's replay_csv function\n",
        "        data = pw.demo.replay_csv(stream_file_path, schema=ParkingSchema, input_rate=1000)\n",
        "\n",
        "        # Add a Timestamp column to the Pathway data stream\n",
        "        fmt = \"%d-%m-%Y %H:%M:%S\"\n",
        "        data_with_time = data.with_columns(\n",
        "            Timestamp=pw.this.LastUpdatedDate + \" \" + pw.this.LastUpdatedTime\n",
        "        ).with_columns(\n",
        "            t=pw.this.Timestamp.dt.strptime(fmt)\n",
        "        )\n",
        "\n",
        "        # --- Pathway Integration for Pricing Models ---\n",
        "\n",
        "        alpha_model1_pw = 0.05\n",
        "\n",
        "        # Model 1 in Pathway\n",
        "        model1_output = data_with_time.with_columns(\n",
        "            Price_Model1 = pw.apply(\n",
        "                lambda occupancy, capacity: model_1_pricing(10.0, occupancy, capacity, alpha_model1_pw),\n",
        "                pw.this.Occupancy, pw.this.Capacity\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Model 2 in Pathway\n",
        "        alpha_model2_pw = 0.1\n",
        "        beta_model2_pw = 0.2\n",
        "        gamma_model2_pw = 0.1\n",
        "        delta_model2_pw = 0.5\n",
        "        epsilon_model2_pw = 0.3\n",
        "        lambda_model2_pw = 0.5\n",
        "\n",
        "        model2_output = model1_output.with_columns(\n",
        "            Price_Model2 = pw.apply(\n",
        "                lambda occupancy, capacity, queue_length, traffic_condition, is_special_day, vehicle_type: model_2_pricing(\n",
        "                    10.0, # Base price\n",
        "                    occupancy,\n",
        "                    capacity,\n",
        "                    queue_length,\n",
        "                    traffic_condition,\n",
        "                    is_special_day,\n",
        "                    vehicle_type,\n",
        "                    lambda_model2_pw,\n",
        "                    alpha_model2_pw,\n",
        "                    beta_model2_pw,\n",
        "                    gamma_model2_pw,\n",
        "                    delta_model2_pw,\n",
        "                    epsilon_model2_pw\n",
        "                ),\n",
        "                pw.this.Occupancy,\n",
        "                pw.this.Capacity,\n",
        "                pw.this.QueueLength,\n",
        "                pw.this.TrafficConditionNearby,\n",
        "                pw.this.IsSpecialDay,\n",
        "                pw.this.VehicleType\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Model 3 in Pathway - Simplified version\n",
        "        # Note: This is a simplified implementation since Model 3 requires competitor data\n",
        "        # In a real streaming scenario, you'd need proper joins with competitor data\n",
        "        model3_output = model2_output.with_columns(\n",
        "            Price_Model3 = pw.apply(\n",
        "                lambda price_model2, occupancy, capacity: price_model2 * (1 + (0.05 if occupancy/capacity > 0.8 else 0)),\n",
        "                pw.this.Price_Model2,\n",
        "                pw.this.Occupancy,\n",
        "                pw.this.Capacity\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Output the results to a CSV file (for demonstration)\n",
        "        pw.io.csv.write(model3_output, stream_output_path)\n",
        "        print(f\"Streaming processing setup completed. Output will be saved to {stream_output_path}\")\n",
        "\n",
        "        return model3_output\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Pathway library not available. Skipping streaming processing.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error in streaming processing: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run both batch and streaming processing\"\"\"\n",
        "    dataset_path = \"/mnt/upload/dataset.csv\"\n",
        "    batch_output_path = \"/mnt/processed_dataset_batch.csv\"\n",
        "    stream_output_path = \"/mnt/processed_dataset_stream.csv\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PARKING PRICING SYSTEM - COMBINED PROCESSING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Run batch processing\n",
        "    print(\"\\n1. BATCH PROCESSING\")\n",
        "    print(\"-\" * 30)\n",
        "    try:\n",
        "        batch_df = batch_processing(dataset_path, batch_output_path)\n",
        "        print(f\"Batch processing successful! Processed {len(batch_df)} records.\")\n",
        "\n",
        "        # Display sample results\n",
        "        print(\"\\nSample batch processing results:\")\n",
        "        print(batch_df[['SystemCodeNumber', 'Occupancy', 'Capacity', 'Price_Model1', 'Price_Model2', 'Price_Model3']].head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Batch processing failed: {e}\")\n",
        "\n",
        "    # Run streaming processing\n",
        "    print(\"\\n2. STREAMING PROCESSING\")\n",
        "    print(\"-\" * 30)\n",
        "    try:\n",
        "        stream_result = streaming_processing(dataset_path, stream_output_path)\n",
        "        if stream_result is not None:\n",
        "            print(\"Streaming processing setup successful!\")\n",
        "        else:\n",
        "            print(\"Streaming processing setup failed or skipped.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Streaming processing failed: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROCESSING COMPLETE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOlNkIlOt1MP",
        "outputId": "2982e3a9-77ac-4440-a1ce-351f8a5f3287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PARKING PRICING SYSTEM - COMBINED PROCESSING\n",
            "============================================================\n",
            "\n",
            "1. BATCH PROCESSING\n",
            "------------------------------\n",
            "Starting batch processing...\n",
            "Batch processing completed. Output saved to /mnt/processed_dataset_batch.csv\n",
            "Batch processing successful! Processed 18368 records.\n",
            "\n",
            "Sample batch processing results:\n",
            "  SystemCodeNumber  Occupancy  Capacity  Price_Model1  Price_Model2  \\\n",
            "0      BHMBCCMKT01         61       577     10.005286     11.365143   \n",
            "1      BHMBCCMKT01         64       577     10.010832     11.365273   \n",
            "2      BHMBCCMKT01         80       577     10.017764     11.415966   \n",
            "3      BHMBCCMKT01        107       577     10.027036     11.417136   \n",
            "4      BHMBCCMKT01        150       577     10.040035     11.381499   \n",
            "\n",
            "   Price_Model3  \n",
            "0     11.365143  \n",
            "1     11.365273  \n",
            "2     11.415966  \n",
            "3     11.417136  \n",
            "4     11.381499  \n",
            "\n",
            "2. STREAMING PROCESSING\n",
            "------------------------------\n",
            "Starting streaming processing with Pathway...\n",
            "Streaming processing setup completed. Output will be saved to /mnt/processed_dataset_stream.csv\n",
            "Streaming processing setup successful!\n",
            "\n",
            "============================================================\n",
            "PROCESSING COMPLETE\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *visualisation.py*"
      ],
      "metadata": {
        "id": "yAt1zfjHvbPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Set style for better-looking plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load the processed dataset\n",
        "df = pd.read_csv(\"/mnt/processed_dataset_batch.csv\")\n",
        "\n",
        "# Convert Timestamp to datetime objects for plotting\n",
        "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
        "\n",
        "# Add derived features for better analysis\n",
        "df['Hour'] = df['Timestamp'].dt.hour\n",
        "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
        "df['OccupancyRate'] = (df['Occupancy'] / df['Capacity']) * 100\n",
        "\n",
        "# Select a few SystemCodeNumbers for plotting\n",
        "sample_system_codes = df[\"SystemCodeNumber\"].unique()[:3]\n",
        "\n",
        "print(f\"Analyzing data for {len(sample_system_codes)} system codes: {sample_system_codes}\")\n",
        "print(f\"Date range: {df['Timestamp'].min()} to {df['Timestamp'].max()}\")\n",
        "\n",
        "# 1. Enhanced Price Comparison Plots\n",
        "for system_code in sample_system_codes:\n",
        "    lot_data = df[df[\"SystemCodeNumber\"] == system_code].sort_values(by=\"Timestamp\")\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "    # Price trends\n",
        "    ax1.plot(lot_data[\"Timestamp\"], lot_data[\"Price_Model1\"],\n",
        "             label=\"Model 1\", linewidth=2, alpha=0.8)\n",
        "    ax1.plot(lot_data[\"Timestamp\"], lot_data[\"Price_Model2\"],\n",
        "             label=\"Model 2\", linewidth=2, alpha=0.8)\n",
        "    ax1.plot(lot_data[\"Timestamp\"], lot_data[\"Price_Model3\"],\n",
        "             label=\"Model 3\", linewidth=2, alpha=0.8)\n",
        "\n",
        "    ax1.set_ylabel(\"Price ($)\", fontsize=12)\n",
        "    ax1.set_title(f\"Parking Price Comparison - System Code: {system_code}\", fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Price difference analysis\n",
        "    lot_data_copy = lot_data.copy()\n",
        "    lot_data_copy['Model1_vs_Model2'] = lot_data_copy['Price_Model1'] - lot_data_copy['Price_Model2']\n",
        "    lot_data_copy['Model1_vs_Model3'] = lot_data_copy['Price_Model1'] - lot_data_copy['Price_Model3']\n",
        "    lot_data_copy['Model2_vs_Model3'] = lot_data_copy['Price_Model2'] - lot_data_copy['Price_Model3']\n",
        "\n",
        "    ax2.plot(lot_data_copy[\"Timestamp\"], lot_data_copy[\"Model1_vs_Model2\"],\n",
        "             label=\"Model 1 - Model 2\", alpha=0.7)\n",
        "    ax2.plot(lot_data_copy[\"Timestamp\"], lot_data_copy[\"Model1_vs_Model3\"],\n",
        "             label=\"Model 1 - Model 3\", alpha=0.7)\n",
        "    ax2.plot(lot_data_copy[\"Timestamp\"], lot_data_copy[\"Model2_vs_Model3\"],\n",
        "             label=\"Model 2 - Model 3\", alpha=0.7)\n",
        "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "    ax2.set_xlabel(\"Time\", fontsize=12)\n",
        "    ax2.set_ylabel(\"Price Difference ($)\", fontsize=12)\n",
        "    ax2.set_title(\"Price Model Differences\", fontsize=12)\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"enhanced_price_comparison_{system_code}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# 2. Enhanced Occupancy Analysis\n",
        "for system_code in sample_system_codes:\n",
        "    lot_data = df[df[\"SystemCodeNumber\"] == system_code].sort_values(by=\"Timestamp\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    # Occupancy vs Capacity\n",
        "    axes[0,0].plot(lot_data[\"Timestamp\"], lot_data[\"Occupancy\"],\n",
        "                   label=\"Occupancy\", color=\"steelblue\", linewidth=2)\n",
        "    axes[0,0].axhline(y=lot_data[\"Capacity\"].iloc[0], color=\"red\",\n",
        "                      linestyle=\"--\", label=\"Capacity\", linewidth=2)\n",
        "    axes[0,0].fill_between(lot_data[\"Timestamp\"], lot_data[\"Occupancy\"],\n",
        "                           alpha=0.3, color=\"steelblue\")\n",
        "    axes[0,0].set_ylabel(\"Count\", fontsize=12)\n",
        "    axes[0,0].set_title(f\"Occupancy vs Capacity - System {system_code}\", fontsize=12, fontweight='bold')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Occupancy Rate\n",
        "    axes[0,1].plot(lot_data[\"Timestamp\"], lot_data[\"OccupancyRate\"],\n",
        "                   color=\"orange\", linewidth=2)\n",
        "    axes[0,1].axhline(y=100, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"100% Capacity\")\n",
        "    axes[0,1].axhline(y=80, color=\"yellow\", linestyle=\"--\", alpha=0.7, label=\"80% Capacity\")\n",
        "    axes[0,1].set_ylabel(\"Occupancy Rate (%)\", fontsize=12)\n",
        "    axes[0,1].set_title(\"Occupancy Rate Over Time\", fontsize=12)\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Queue Length\n",
        "    axes[1,0].plot(lot_data[\"Timestamp\"], lot_data[\"QueueLength\"],\n",
        "                   color=\"purple\", linewidth=2)\n",
        "    axes[1,0].fill_between(lot_data[\"Timestamp\"], lot_data[\"QueueLength\"],\n",
        "                           alpha=0.3, color=\"purple\")\n",
        "    axes[1,0].set_xlabel(\"Time\", fontsize=12)\n",
        "    axes[1,0].set_ylabel(\"Queue Length\", fontsize=12)\n",
        "    axes[1,0].set_title(\"Queue Length Trend\", fontsize=12)\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Hourly patterns\n",
        "    hourly_avg = lot_data.groupby('Hour').agg({\n",
        "        'OccupancyRate': 'mean',\n",
        "        'QueueLength': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    ax_twin = axes[1,1]\n",
        "    ax_twin2 = ax_twin.twinx()\n",
        "\n",
        "    line1 = ax_twin.bar(hourly_avg['Hour'], hourly_avg['OccupancyRate'],\n",
        "                        alpha=0.7, color='steelblue', label='Avg Occupancy Rate')\n",
        "    line2 = ax_twin2.plot(hourly_avg['Hour'], hourly_avg['QueueLength'],\n",
        "                          color='red', marker='o', linewidth=2, label='Avg Queue Length')\n",
        "\n",
        "    ax_twin.set_xlabel(\"Hour of Day\", fontsize=12)\n",
        "    ax_twin.set_ylabel(\"Occupancy Rate (%)\", fontsize=12, color='steelblue')\n",
        "    ax_twin2.set_ylabel(\"Average Queue Length\", fontsize=12, color='red')\n",
        "    ax_twin.set_title(\"Hourly Usage Patterns\", fontsize=12)\n",
        "    ax_twin.grid(True, alpha=0.3)\n",
        "\n",
        "    # Combine legends\n",
        "    lines1, labels1 = ax_twin.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax_twin2.get_legend_handles_labels()\n",
        "    ax_twin.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"enhanced_occupancy_analysis_{system_code}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# 3. Summary Statistics and Correlation Analysis\n",
        "print(\"\\n=== SUMMARY STATISTICS ===\")\n",
        "for system_code in sample_system_codes:\n",
        "    lot_data = df[df[\"SystemCodeNumber\"] == system_code]\n",
        "\n",
        "    print(f\"\\nSystem Code: {system_code}\")\n",
        "    print(f\"Average Occupancy Rate: {lot_data['OccupancyRate'].mean():.1f}%\")\n",
        "    print(f\"Peak Occupancy Rate: {lot_data['OccupancyRate'].max():.1f}%\")\n",
        "    print(f\"Average Queue Length: {lot_data['QueueLength'].mean():.1f}\")\n",
        "    print(f\"Max Queue Length: {lot_data['QueueLength'].max()}\")\n",
        "\n",
        "    # Price statistics\n",
        "    price_cols = ['Price_Model1', 'Price_Model2', 'Price_Model3']\n",
        "    for col in price_cols:\n",
        "        print(f\"{col} - Mean: ${lot_data[col].mean():.2f}, Std: ${lot_data[col].std():.2f}\")\n",
        "\n",
        "# 4. Correlation Analysis\n",
        "correlation_data = df[['Price_Model1', 'Price_Model2', 'Price_Model3',\n",
        "                       'Occupancy', 'QueueLength', 'OccupancyRate']].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix: Prices, Occupancy, and Queue Length\", fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"correlation_matrix.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPwPSJW3ufY3",
        "outputId": "b8c0a754-2f61-4c89-f495-36a27cb1410c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing data for 3 system codes: ['BHMBCCMKT01' 'BHMBCCTHL01' 'BHMEURBRD01']\n",
            "Date range: 2016-10-04 07:59:00 to 2016-12-19 16:30:00\n",
            "\n",
            "=== SUMMARY STATISTICS ===\n",
            "\n",
            "System Code: BHMBCCMKT01\n",
            "Average Occupancy Rate: 28.1%\n",
            "Peak Occupancy Rate: 99.3%\n",
            "Average Queue Length: 3.6\n",
            "Max Queue Length: 11\n",
            "Price_Model1 - Mean: $19.24, Std: $5.31\n",
            "Price_Model2 - Mean: $11.50, Std: $0.12\n",
            "Price_Model3 - Mean: $11.50, Std: $0.15\n",
            "\n",
            "System Code: BHMBCCTHL01\n",
            "Average Occupancy Rate: 74.5%\n",
            "Peak Occupancy Rate: 104.1%\n",
            "Average Queue Length: 4.1\n",
            "Max Queue Length: 12\n",
            "Price_Model1 - Mean: $32.84, Std: $13.92\n",
            "Price_Model2 - Mean: $11.54, Std: $0.13\n",
            "Price_Model3 - Mean: $11.35, Std: $0.40\n",
            "\n",
            "System Code: BHMEURBRD01\n",
            "Average Occupancy Rate: 64.4%\n",
            "Peak Occupancy Rate: 100.0%\n",
            "Average Queue Length: 4.0\n",
            "Max Queue Length: 11\n",
            "Price_Model1 - Mean: $30.99, Std: $12.26\n",
            "Price_Model2 - Mean: $11.53, Std: $0.12\n",
            "Price_Model3 - Mean: $11.27, Std: $0.46\n"
          ]
        }
      ]
    }
  ]
}
